input{
    kafka{
        bootstrap_servers => ["192.168.100.133:9092"]
        topics => ["erp_nginx_test"]
        session_timeout_ms => "36000"
        auto_offset_reset => "latest"
        consumer_threads =>2
        decorate_events =>true
        type => "erp-nginx-test"
        group_id => "logstash"
        client_id => "client1"
        max_poll_records => "550"
        max_poll_interval_ms => "300000"
    }

    kafka{
        bootstrap_servers => ["192.168.100.133:9092"]
        topics => ["erp_nginx_prod"]
        session_timeout_ms => "36000"
        auto_offset_reset => "latest"
        consumer_threads =>6
        decorate_events =>true
        type => "erp-nginx-prod"
        group_id => "logstash"
        client_id => "client1"
        max_poll_records => "550"
        max_poll_interval_ms => "300000"
    }

    kafka{
        bootstrap_servers => ["192.168.100.133:9092"]
        topics => ["erp_odoo_prod"]
        session_timeout_ms => "36000"
        consumer_threads =>6
        decorate_events =>true
        type => "erp-odoo-prod"
        group_id => "logstash"
        client_id => "client1"
        auto_offset_reset => "earliest"
        max_poll_records => "550"
        max_poll_interval_ms => "300000"
    }

    # kafka{
    #     bootstrap_servers => ["192.168.100.133:9092"]
    #     topics => ["erp_odoo_test"]
    #     session_timeout_ms => "36000"
    #     auto_offset_reset => "latest"
    #     consumer_threads =>2
    #     decorate_events =>true
    #     type => "erp-odoo-test"
    #     group_id => "logstash"
    #     client_id => "client1"
    # }

    # kafka{
    #     bootstrap_servers => ["192.168.100.133:9092"]
    #     topics => ["erp_slow_test"]
    #     session_timeout_ms => "36000"
    #     auto_offset_reset => "latest"
    #     consumer_threads =>2
    #     decorate_events =>true
    #     type => "erp-slow-test"
    #     group_id => "logstash"
    #     client_id => "client1"
    # }

   kafka{
       bootstrap_servers => ["192.168.100.133:9092"]
       topics => ["erp_slow_prod"]
       session_timeout_ms => "36000"
       consumer_threads =>6
       decorate_events =>true
       type => "erp-slow-prod"
       group_id => "logstash"
       client_id => "client1"
       max_poll_records => "550"
       max_poll_interval_ms => "300000"
   }
   kafka{
       bootstrap_servers => ["192.168.100.133:9092"]
       topics => ["erp_auditlog_prod"]
       session_timeout_ms => "36000"
       consumer_threads =>6
       decorate_events =>true
       type => "erp-auditlog-prod"
       group_id => "logstash"
       client_id => "client1"
       max_poll_records => "550"
       max_poll_interval_ms => "300000"
       codec => json {
           charset => "UTF-8"
       }
   }
   kafka{
       bootstrap_servers => ["192.168.100.133:9092"]
       topics => ["erp_auditlog_test"]
       session_timeout_ms => "36000"
       consumer_threads =>6
       decorate_events =>true
       type => "erp-auditlog-test"
       group_id => "logstash"
       client_id => "client1"
       max_poll_records => "550"
       max_poll_interval_ms => "300000"
       codec => json {
           charset => "UTF-8"
       }
   }
   kafka{
       bootstrap_servers => ["192.168.100.133:9092"]
       topics => ["erp_httplog_prod"]
       session_timeout_ms => "36000"
       consumer_threads =>6
       decorate_events =>true
       type => "erp-httplog-prod"
       group_id => "logstash"
       client_id => "client1"
       max_poll_records => "550"
       max_poll_interval_ms => "300000"
       codec => json {
           charset => "UTF-8"
       }
   }
}

filter {
    mutate {
	rename => { "type" => "log_type" }
    }

    if [log_type] == "erp-auditolog-test" or [log_type] == "erp-auditlog-prod" or [log_type] == "erp-httplog-prod" {
        json {
            source => "message"
            target => "message"
        }
    }else{
        json {
            source => "message"
        }
    }

    mutate{
	remove_field => "offset"
	remove_field => "kafka"
	remove_field => "@version"
	remove_field => "input_type"
	# remove_field => "source"
	remove_field => "fields"
	remove_field => "type"
	remove_field => "_id"
	remove_field => "_score"
	remove_field => "_type"
	remove_field => "ecs"
	remove_field => "agent"
	remove_field => "cloud"
	remove_field => "agent.ephemeral_id"
	remove_field => "agent.type"
	remove_field => "agent.version"
	remove_field => "ecs.version"
    }

    if [log_type] == "erp-odoo-test" or [log_type] == "erp-odoo-prod" {
        grok {
            patterns_dir => "/usr/share/logstash/patterns"
            match => { 'message' => '%{ODOOLOG}' }
            remove_field => "message"
        }
        date {
            match => ["odoo_timestamp", "yyyy-MM-dd HH:mm:ss,SSS"]
            timezone => "UTC"
            target => "@timestamp"
        }
    }else if [log_type] == "erp-nginx-test" or [log_type] == "erp-nginx-prod" {
        grok {
            match => {'message' => '%{IPORHOST:remote_addr} - %{USERNAME:remote_user} \[%{HTTPDATE:time_local}\] \"%{DATA:request}\"(| )%{INT:status} %{NUMBER:bytes_sent} \"%{DATA:http_referer}\" \"%{DATA:http_user_agent}\" \"%{DATA:http_x_forward_for}\" \"%{DATA:upstream_addr}\" (%{NUMBER:upstream_response_time}|-) (%{NUMBER:request_time}|-)'}
            remove_field => "message"
        }
        date {
             match => [ "time_local", "dd/MMM/yyyy:HH:mm:ss +0800" ]
             # timezone => "UTC"
             timezone => "+0800"
             target => "@timestamp"
	}
    }else if [log_type] == "erp-slow-test" or [log_type] == "erp-slow-prod"{
       grok {
          patterns_dir => "/usr/share/logstash/patterns"
          match => {
              'message' => '%{SQLLOG}|%{JSONREQUEST}|%{HTTPREQUEST}'
          }
          remove_field => "message"
       }
      date {
          match => ["odoo_timestamp", "yyMMdd HH:mm:ss"]
          timezone => "UTC"
          target => "@timestamp"
      }
    }else if [log_type] == "erp-auditolog-test" or [log_type] == "erp-auditlog-prod" {
    }
}


output {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "%{[log_type]}-%{+YYYY.MM.dd}"
        template=>"/usr/share/logstash/patterns/template/slow.json"
        template_name=>"slow_template"
        template_overwrite=>true
        user => elastic
        password => ODOO123
    }

  # file{
  #   path => "/tmp/out.txt"
  #  }
}
